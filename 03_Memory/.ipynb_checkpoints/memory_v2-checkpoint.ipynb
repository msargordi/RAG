{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "8uS3H8y-DKdu",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "! pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain langchain_fireworks google-search-results requests gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 224,
     "status": "ok",
     "timestamp": 1722518802046,
     "user": {
      "displayName": "Maziar Sargordi",
      "userId": "18222397832012180721"
     },
     "user_tz": 240
    },
    "id": "pO8Bp6MTDVLf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['FIREWORKS_API_KEY'] = 'API_KEY'\n",
    "os.environ[\"SERPER_API_KEY\"] = 'API_KEY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "executionInfo": {
     "elapsed": 2006,
     "status": "ok",
     "timestamp": 1722520473623,
     "user": {
      "displayName": "Maziar Sargordi",
      "userId": "18222397832012180721"
     },
     "user_tz": 240
    },
    "id": "ZCCBygRTzRQq",
    "outputId": "672509cf-53e9-4d70-8051-f123226ade95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
      "Running on public URL: https://303d74ff7cdb6fbfee.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://303d74ff7cdb6fbfee.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "from langchain_fireworks import ChatFireworks\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import gradio as gr\n",
    "import os\n",
    "\n",
    "\n",
    "# Set up the prompt template\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessage(content=\"You are a chatbot having a conversation with a human. You might have multiple sessions but you can use previous chats if necessary.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{human_input}\")\n",
    "])\n",
    "\n",
    "# Initialize the language model\n",
    "llm = ChatFireworks(model_name=\"accounts/fireworks/models/llama-v3p1-70b-instruct\", temperature=0.3)\n",
    "\n",
    "# Initialize memory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# Create the conversation chain\n",
    "chat_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory,\n",
    ")\n",
    "\n",
    "def chat(message, history):\n",
    "    response = chat_chain.predict(human_input=message)\n",
    "    history.append((message, response))\n",
    "    return \"\", history\n",
    "\n",
    "def new_chat():\n",
    "    chat_chain.predict(human_input=\"[NEW CHAT SESSION]\")\n",
    "    return None, []\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot()\n",
    "    msg = gr.Textbox()\n",
    "    clear = gr.Button(\"New Chat\")\n",
    "\n",
    "    msg.submit(chat, [msg, chatbot], [msg, chatbot])\n",
    "    clear.click(new_chat, outputs=[msg, chatbot])\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1722519222814,
     "user": {
      "displayName": "Maziar Sargordi",
      "userId": "18222397832012180721"
     },
     "user_tz": 240
    },
    "id": "hHqzL9DsIips"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPNfyqwbfK/b7TiFMcxc0Br",
   "provenance": [
    {
     "file_id": "1syTT0eVcED4WwnftnpeH-y0vfdvfGVRB",
     "timestamp": 1722459069566
    },
    {
     "file_id": "16cbyPDOSqUShgvYeiK1jbtYBkzbK15us",
     "timestamp": 1722366099137
    },
    {
     "file_id": "1rjo4NNhfvSdBMPoGROW-lvwT9oLbR-PM",
     "timestamp": 1722357676502
    },
    {
     "file_id": "1pvUJLSQMwmwe-wo6JsZHt-Kh0tHp8JeM",
     "timestamp": 1722294345788
    },
    {
     "file_id": "1xMS4sulBD56oy7VHih-bdwaD3TN2l1tH",
     "timestamp": 1722288913723
    },
    {
     "file_id": "1aRrGzH8tc8b2cibEzz3RobyA4HOVgQLj",
     "timestamp": 1722283659675
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
